{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Leer el archivo CSV de titulados ed_sup 2022\n",
    "part1 = pd.read_csv('part1.csv')\n",
    "part2 = pd.read_csv('part2.csv')\n",
    "part3 = pd.read_csv('part3.csv')\n",
    "part4 = pd.read_csv('part4.csv')\n",
    "df_titulados = pd.concat([part1, part2, part3, part4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titulados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas2015 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2015_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2016 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2016_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2017 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2017_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2018 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2018_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2019 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2019_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2020 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2020_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2015_2020 = pd.concat([df_notas2015, df_notas2016, df_notas2017, df_notas2018, df_notas2019, df_notas2020])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas2015_2020.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesado titulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos el tamaño para saber las dimensiones en futuras referencias\n",
    "df_titulados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluamos las columnas para ver que utilizaremos\n",
    "df_titulados.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decidimos eliminar las columnas que no vemos util\n",
    "columnas_a_eliminar = ['fec_nac_alu','anio_ing_carr_ori','sem_ing_carr_ori','sem_ing_carr_act','fecha_obtencion_titulo','cod_inst','cod_sede','cod_carrera','dur_proceso_tit','provincia_sede','comuna_sede','version','tipo_plan_carr','area_cineunesco','area_cine_f_97','subarea_cine_f_97','area_cine_f_13','subarea_cine_f_13','area_carrera_generica_n']\n",
    "df_titulados.drop(columns=columnas_a_eliminar, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluamos si hay nulos\n",
    "df_titulados.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notamos que mrun tiene nulos lo cual no lo consideraremos ya que son necesarios para un merge a futuro que haremos\n",
    "df_titulados.dropna(subset=[\"mrun\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tambien notamos que hay muchos nulos en nombres de itulos obtenidos, lo que asumimos que no lo consiguieron.\n",
    "# por lo que lo rellenaremos como no completados\n",
    "df_titulados[\"nomb_titulo_obtenido\"].fillna('No completado', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lo mismo para el nombre de grado obtenido\n",
    "df_titulados[\"nomb_grado_obtenido\"].fillna('Grado superior no obtenido', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobamos si hay duplicados\n",
    "df_titulados.duplicated().sum()\n",
    "df_titulados.drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora vemos si los tippos de datos son los correctos en las columnas y si son necesarios cambiarlos \n",
    "df_titulados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necesitamos el mrun como int para el merge\n",
    "\n",
    "# Asegurarse de que sea de tipo int64\n",
    "df_titulados['mrun'] = df_titulados['mrun'].astype(np.int64)\n",
    "\n",
    "# Verificar el tipo de datos de la columna\n",
    "print(\"verificamos si es de tipo int64:\", df_titulados['mrun'].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesado notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas2015_2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas2015_2020.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decidimos eliminar las columnas que no vemos util\n",
    "columnas_a_eliminar = ['DGV_RBD','COD_REG_RBD','RBD','NOM_REG_RBD_A','COD_PRO_RBD','COD_COM_RBD','NOM_COM_RBD','COD_DEPROV_RBD','NOM_DEPROV_RBD']\n",
    "df_notas2015_2020.drop(columns=columnas_a_eliminar, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluamos si hay nulos\n",
    "df_notas2015_2020.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobamos si hay duplicados\n",
    "df_notas2015_2020.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora vemos si los tippos de datos son los correctos en las columnas y si son necesarios cambiarlos \n",
    "# (veremos en el codigo mas adelante si son necesarios)\n",
    "df_notas2015_2020.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensando en el merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas=pd.merge(df_notas2015_2020,df_titulados, left_on=\"MRUN\",right_on=\"mrun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#decidimos eliminar las columnas que no vemos util\n",
    "columnas_a_eliminar = ['COD_GRADO','MRUN','codigo_unico','mrun','rango_edad','nomb_titulo_obtenido','tipo_inst_1','tipo_inst_2','tipo_inst_3','nomb_inst','nomb_sede','nomb_carrera','nivel_global','dur_estudio_carr','dur_total_carr','region_sede','jornada','modalidad','ORIGEN','nivel_carrera_1','nomb_grado_obtenido']\n",
    "df_merge_titulados_notas.drop(columns=columnas_a_eliminar, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las filas donde ENSE_COMPLETA es 0 asegurandonos de tratar con casos de egresados\n",
    "df_merge_titulados_notas.drop(df_merge_titulados_notas[df_merge_titulados_notas['ENSE_COMPLETA'] == 0].index, inplace=True)\n",
    "\n",
    "# Verificar el resultado\n",
    "df_merge_titulados_notas[df_merge_titulados_notas[\"ENSE_COMPLETA\"]==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tener ojo con los tipos de datos para futuras referencias de tipos de datos\n",
    "df_merge_titulados_notas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar comas por puntos\n",
    "df_merge_titulados_notas['PROM_NOTAS_ALU'] = df_merge_titulados_notas['PROM_NOTAS_ALU'].str.replace(',', '.')\n",
    "\n",
    "# Asegurarse de que la columna sea de tipo float64\n",
    "df_merge_titulados_notas['PROM_NOTAS_ALU'] = df_merge_titulados_notas['PROM_NOTAS_ALU'].astype(np.float64)\n",
    "\n",
    "# Verificar el tipo de datos de la columna\n",
    "print(\"verificamos si es de tipo float64:\", df_merge_titulados_notas['PROM_NOTAS_ALU'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicio modelos de clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Supongamos que ya tienes el DataFrame cargado como df_merge_titulados_notas\n",
    "# df_merge_titulados_notas = pd.read_csv('ruta_al_archivo.csv')  # Si necesitas cargar el archivo\n",
    "\n",
    "# Filtrar el DataFrame para eliminar las filas donde ENSE_COMPLETA es 0\n",
    "df_merge_titulados_notas.drop(df_merge_titulados_notas[df_merge_titulados_notas['ENSE_COMPLETA'] == 0].index, inplace=True)\n",
    "\n",
    "# Seleccionar características relevantes\n",
    "features = ['PROM_NOTAS_ALU', 'COD_ENSE', 'cat_periodo']\n",
    "\n",
    "# Filtrar el DataFrame para obtener solo las características y la etiqueta\n",
    "df = df_merge_titulados_notas[features + ['nivel_carrera_2']]\n",
    "\n",
    "# Separar características y etiqueta\n",
    "X = df[features]  # Aquí se asegura de que todas las características sean usadas\n",
    "y = df['nivel_carrera_2']\n",
    "\n",
    "# Dividir el conjunto de datos en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelo: Árbol de Decisión\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "accuracy_tree = accuracy_score(y_test, y_pred_tree)\n",
    "print(f'Precisión del modelo de Árbol de Decisión: {accuracy_tree:.2f}')\n",
    "\n",
    "# Visualizar la matriz de confusión para el modelo de Árbol de Decisión\n",
    "cm_tree = confusion_matrix(y_test, y_pred_tree, labels=tree_clf.classes_)\n",
    "disp_tree = ConfusionMatrixDisplay(confusion_matrix=cm_tree, display_labels=tree_clf.classes_)\n",
    "disp_tree.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusión para el Modelo de Árbol de Decisión')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cargar el conjunto de datos de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Crear un DataFrame a partir de los datos de iris\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['target'] = iris.target\n",
    "\n",
    "# Dividir las características y la variable objetivo\n",
    "X = df[iris.feature_names]\n",
    "y = df['target']\n",
    "\n",
    "# Dividir el conjunto de datos en conjunto de entrenamiento y conjunto de prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el modelo Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir con el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Precisión del modelo: {accuracy:.2f}')\n",
    "\n",
    "# Visualizar las predicciones con una matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred, labels=model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=iris.target_names)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusión para las Predicciones del Modelo Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# Visualizar las predicciones con gráficos de dispersión\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i, feature in enumerate(iris.feature_names, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "    sns.scatterplot(x=X_test[feature], y=y_test, label='Real', marker='o')\n",
    "    sns.scatterplot(x=X_test[feature], y=y_pred, label='Predicho', marker='x')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Target')\n",
    "    plt.title(f'Predicción vs Realidad en {feature}')\n",
    "    plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
