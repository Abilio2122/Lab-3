{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acá importamos los csv, hice particioes de el csv titulados para que se maneje en entorno github sin problemas de tamaño"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Leer el archivo CSV de titulados ed_sup 2022\n",
    "part1 = pd.read_csv('part1.csv')\n",
    "part2 = pd.read_csv('part2.csv')\n",
    "part3 = pd.read_csv('part3.csv')\n",
    "part4 = pd.read_csv('part4.csv')\n",
    "df_titulados = pd.concat([part1, part2, part3, part4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titulados.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora importamos los csv de notas y los concatenamos entre ellos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas2015 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2015_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2016 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2016_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2017 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2017_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2018 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2018_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2019 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2019_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2020 = pd.read_csv('20240404 Notas y Egresados EnseñanzaMedia 2020_WEB.csv',sep=\";\", encoding='latin1')\n",
    "df_notas2015_2020 = pd.concat([df_notas2015, df_notas2016, df_notas2017, df_notas2018, df_notas2019, df_notas2020])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas2015_2020.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesado titulados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vemos el tamaño para saber las dimensiones en futuras referencias\n",
    "df_titulados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluamos las columnas para ver que utilizaremos\n",
    "df_titulados.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decidimos eliminar las columnas que no vemos util\n",
    "columnas_a_eliminar = ['fec_nac_alu','anio_ing_carr_ori','sem_ing_carr_ori','sem_ing_carr_act','fecha_obtencion_titulo','cod_inst','cod_sede','cod_carrera','dur_proceso_tit','provincia_sede','comuna_sede','version','tipo_plan_carr','area_cineunesco','area_cine_f_97','subarea_cine_f_97','area_cine_f_13','subarea_cine_f_13','area_carrera_generica_n']\n",
    "df_titulados.drop(columns=columnas_a_eliminar, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluamos si hay nulos\n",
    "df_titulados.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notamos que mrun tiene nulos lo cual no lo consideraremos ya que son necesarios para un merge a futuro que haremos\n",
    "df_titulados.dropna(subset=[\"mrun\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tambien notamos que hay muchos nulos en nombres de itulos obtenidos, lo que asumimos que no lo consiguieron.\n",
    "# por lo que lo rellenaremos como no completados\n",
    "df_titulados[\"nomb_titulo_obtenido\"].fillna('No completado', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lo mismo para el nombre de grado obtenido\n",
    "df_titulados[\"nomb_grado_obtenido\"].fillna('Grado superior no obtenido', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobamos si hay duplicados\n",
    "df_titulados.duplicated().sum()\n",
    "df_titulados.drop_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora vemos si los tippos de datos son los correctos en las columnas y si son necesarios cambiarlos \n",
    "df_titulados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#necesitamos el mrun como int para el merge\n",
    "\n",
    "# Asegurarse de que sea de tipo int64\n",
    "df_titulados['mrun'] = df_titulados['mrun'].astype(np.int64)\n",
    "\n",
    "# Verificar el tipo de datos de la columna\n",
    "print(\"verificamos si es de tipo int64:\", df_titulados['mrun'].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesado notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas2015_2020.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_notas2015_2020.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decidimos eliminar las columnas que no vemos util\n",
    "columnas_a_eliminar = ['DGV_RBD','COD_REG_RBD','RBD','COD_PRO_RBD','COD_COM_RBD','NOM_COM_RBD','COD_DEPROV_RBD','NOM_DEPROV_RBD']\n",
    "df_notas2015_2020.drop(columns=columnas_a_eliminar, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluamos si hay nulos\n",
    "df_notas2015_2020.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobamos si hay duplicados\n",
    "df_notas2015_2020.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora vemos si los tippos de datos son los correctos en las columnas y si son necesarios cambiarlos \n",
    "# (veremos en el codigo mas adelante si son necesarios)\n",
    "df_notas2015_2020.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pensando en el merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hacemos merge entre los 2 df concatenados y preprocesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas=pd.merge(df_notas2015_2020,df_titulados, left_on=\"MRUN\",right_on=\"mrun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decidimos eliminar las columnas que no vemos util, hacemos una version con regiones que usaremos mas adelante\n",
    "columnas_a_eliminar = ['COD_GRADO','MRUN','codigo_unico','mrun','rango_edad','nomb_titulo_obtenido','tipo_inst_1','tipo_inst_2','tipo_inst_3','nomb_inst','nomb_sede','nomb_carrera','nivel_global','dur_estudio_carr','dur_total_carr','region_sede','jornada','modalidad','ORIGEN','nivel_carrera_1','nomb_grado_obtenido']\n",
    "df_regiones=df_merge_titulados_notas.drop(columns=columnas_a_eliminar)\n",
    "\n",
    "\n",
    "#decidimos eliminar las columnas que no vemos util\n",
    "columnas_a_eliminar = ['COD_GRADO','MRUN','codigo_unico','mrun','rango_edad','nomb_titulo_obtenido','tipo_inst_1','tipo_inst_2','tipo_inst_3','nomb_inst','nomb_sede','nomb_carrera','nivel_global','dur_estudio_carr','dur_total_carr','region_sede','jornada','modalidad','ORIGEN','nivel_carrera_1','nomb_grado_obtenido','NOM_REG_RBD_A']\n",
    "df_merge_titulados_notas.drop(columns=columnas_a_eliminar, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas=pd.merge(df_notas2015_2020,df_titulados, left_on=\"MRUN\",right_on=\"mrun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#decidimos eliminar las columnas que no vemos util\n",
    "columnas_a_eliminar = ['COD_GRADO','MRUN','codigo_unico','mrun','rango_edad','nomb_titulo_obtenido','tipo_inst_1','tipo_inst_2','tipo_inst_3','nomb_inst','nomb_sede','nomb_carrera','nivel_global','dur_estudio_carr','dur_total_carr','region_sede','jornada','modalidad','ORIGEN','nivel_carrera_1','nomb_grado_obtenido']\n",
    "df_regiones=df_merge_titulados_notas.drop(columns=columnas_a_eliminar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas=pd.merge(df_notas2015_2020,df_titulados, left_on=\"MRUN\",right_on=\"mrun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las filas donde ENSE_COMPLETA es 0 asegurandonos de tratar con casos de egresados\n",
    "df_merge_titulados_notas.drop(df_merge_titulados_notas[df_merge_titulados_notas['MARCA_EGRESO'] == 0].index, inplace=True)\n",
    "\n",
    "# Verificar el resultado\n",
    "df_merge_titulados_notas[df_merge_titulados_notas[\"MARCA_EGRESO\"]==0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las filas donde ENSE_COMPLETA es 0 asegurandonos de tratar con casos de egresados\n",
    "df_regiones.drop(df_regiones[df_regiones['MARCA_EGRESO'] == 0].index, inplace=True)\n",
    "\n",
    "# Verificar el resultado\n",
    "df_regiones[df_regiones[\"MARCA_EGRESO\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_titulados_notas.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tener ojo con los tipos de datos para futuras referencias de tipos de datos\n",
    "df_merge_titulados_notas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar comas por puntos\n",
    "df_merge_titulados_notas['PROM_NOTAS_ALU'] = df_merge_titulados_notas['PROM_NOTAS_ALU'].str.replace(',', '.')\n",
    "\n",
    "# Asegurarse de que la columna sea de tipo float64\n",
    "df_merge_titulados_notas['PROM_NOTAS_ALU'] = df_merge_titulados_notas['PROM_NOTAS_ALU'].astype(np.float64)\n",
    "\n",
    "# Verificar el tipo de datos de la columna\n",
    "print(\"verificamos si es de tipo float64:\", df_merge_titulados_notas['PROM_NOTAS_ALU'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aca exportamos el dataframe preprocesado para trabajar en entorno colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_merge_titulados_notas.to_csv('df_merge_titulados_notas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_regiones.to_csv('df_regiones.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
